{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import lines, markers\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import glob \n",
    "import re\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "import subprocess\n",
    "from itertools import cycle\n",
    "from math import floor, ceil, sqrt\n",
    "plt.style.use('ggplot')\n",
    "sns.choose_colorbrewer_palette('qualitative')\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['hatch.linewidth'] = 0.2\n",
    "matplotlib.rcParams['xtick.labelsize'] = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentParameter:\n",
    "    def __init__(self, key, units, label=None, name=None, timeSeries=True, componentAggregation=np.sum, queryAggregation=np.sum, executionAggregation=np.mean):\n",
    "        self.key = key\n",
    "        self.units = units\n",
    "        self.label = key if label is None else label\n",
    "        self.name = key if name is None else name\n",
    "        self.timeSeries = timeSeries\n",
    "        self.executionAggregation = executionAggregation\n",
    "        self.queryAggregation = queryAggregation\n",
    "        self.componentAggregation = componentAggregation\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'{self.label} ({self.units})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_PERCENTAGE = 0.1\n",
    "COOLDOWN_PERCENTAGE = 0.1\n",
    "OUTPUT_DIRECTORY=''\n",
    "COMMIT = ''\n",
    "REPORT_FOLDER=''\n",
    "DATA = None\n",
    "PARAMETER_LABELS = {'rate': 'Rate (t/s)', 'latency': 'Latency (s)', 'cpu': 'CPU (%)', 'memory': 'Memory (MB)'}\n",
    "\n",
    "\n",
    "TEXT_FIGURES_PATH='data/output'\n",
    "\n",
    "def selectOutput(outputType):\n",
    "    global OUTPUT_DIRECTORY\n",
    "    OUTPUT_DIRECTORY=f'data/{outputType}'\n",
    "    interact(selectCommit, commitID=sortedLsByTime(OUTPUT_DIRECTORY))\n",
    "    \n",
    "def sortedLsByTime(path):\n",
    "    try:\n",
    "        mtime = lambda f: os.stat(os.path.join(path, f)).st_mtime\n",
    "        dirs = list(sorted(os.listdir(path), key=mtime, reverse=True))\n",
    "        return [directory for directory in dirs if os.path.isdir(os.path.join(path, directory))]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "    \n",
    "def selectCommit(commitID):\n",
    "    global COMMIT\n",
    "    if commitID:\n",
    "        COMMIT=commitID.split('/')[-1]\n",
    "        \n",
    "def loadData(folder):\n",
    "    global DATA\n",
    "    \n",
    "    def removeWarmupCooldown(df):\n",
    "        tmax = df.t.max()\n",
    "        warmup = floor(tmax * WARMUP_PERCENTAGE)\n",
    "        cooldown = ceil(tmax - tmax * COOLDOWN_PERCENTAGE)\n",
    "        df.loc[(df.t < warmup) | (df.t > cooldown), 'value'] = np.nan\n",
    "        return df\n",
    "    \n",
    "    def subtractMin(df, key):\n",
    "        df[key] -= df[key].min()\n",
    "        return df\n",
    "\n",
    "    def readCsv(file):\n",
    "        if not file:\n",
    "            return pd.DataFrame()\n",
    "        df = pd.read_csv(f'{file}', names=('rep', 'parallelism', 'node', 'idx', 't', 'value'))\n",
    "        df['rep'] = df['rep'].astype(int)\n",
    "        df['parallelism'] = df['parallelism'].astype(int)\n",
    "        df['value'] = df['value'].astype(float)\n",
    "        df['t'] = df['t'].astype(int)\n",
    "        df = df.groupby(['rep', 'parallelism']).apply(subtractMin, key='t')\n",
    "        df = df.groupby(['rep', 'parallelism']).apply(removeWarmupCooldown)\n",
    "        return df\n",
    "\n",
    "    dataFrames = []\n",
    "    for experimentDir in os.listdir(REPORT_FOLDER):\n",
    "        if not os.path.isdir(REPORT_FOLDER + '/' + experimentDir):\n",
    "            continue\n",
    "        experimentName, experimentVariant = experimentDir.split('_')\n",
    "        for dataFile in glob.glob(REPORT_FOLDER + '/' + experimentDir + '/' + '*.csv'):\n",
    "            parameter = dataFile.split('/')[-1].split('.')[0]\n",
    "            try:\n",
    "                df = readCsv(dataFile)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to read {dataFile}')\n",
    "                continue\n",
    "            df['parameter'] = parameter\n",
    "            df['experiment'] = experimentName\n",
    "            df['variant'] = experimentVariant\n",
    "            dataFrames.append(df)\n",
    "    DATA = pd.concat(dataFrames, sort=False)\n",
    "        \n",
    "def on_button_clicked(b):\n",
    "    global REPORT_FOLDER\n",
    "    REPORT_FOLDER = f'{OUTPUT_DIRECTORY}/{COMMIT}'\n",
    "    loadData(REPORT_FOLDER)\n",
    "    print(f'Done!')\n",
    "    \n",
    "\n",
    "interact(selectOutput, outputType={'local': 'output'})\n",
    "\n",
    "button = widgets.Button(description=\"Load Data\")\n",
    "button.on_click(on_button_clicked)\n",
    "display(button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(**kwargs):\n",
    "    if len(kwargs) == 0:\n",
    "        raise ValueError('Need at least one argument!')\n",
    "    queryParts = []\n",
    "    for key, value in kwargs.items():\n",
    "        queryParts.append(f'({key} == \"{value}\")')\n",
    "    queryStr = ' & '.join(queryParts)\n",
    "    return DATA.query(queryStr)\n",
    "\n",
    "\n",
    "def percentageDiff(value, reference):\n",
    "    return 100*(value - reference) / reference\n",
    "\n",
    "def get95CI(data):\n",
    "    return (1.96*np.std(data))/np.sqrt(len(data))\n",
    "\n",
    "def expandSyntheticCols(df):\n",
    "    df = df.copy()\n",
    "    df[['variant', 'sourceParallelism', 'sinkParallelism', 'provenanceOverlap','provenanceSize']] = df.variant.str.split('\\.', expand=True)\n",
    "    df[['sourceParallelism', 'sinkParallelism', 'provenanceOverlap', 'provenanceSize']] = df[['sourceParallelism', 'sinkParallelism', 'provenanceOverlap','provenanceSize']].apply(pd.to_numeric)\n",
    "    return df\n",
    "\n",
    "    \n",
    "SYSTEM_PARAMETERS = ['gc_count_old', 'gc_count_young', 'gc_time_old', 'gc_time_young', 'memory']\n",
    "DATA['kind'] = 'user'\n",
    "DATA.loc[DATA['parameter'].isin(SYSTEM_PARAMETERS), 'kind'] = 'system'\n",
    "# Extract transparent/non-transparent variant ending in 1 or 2\n",
    "DATA['transparent'] = DATA['variant'].str.contains('[a-zA-Z]+2[a-zA-Z]?$', regex=True)\n",
    "DATA['variant'] = DATA['variant'].str.replace('^GL\\d$', 'GL', regex=True)\n",
    "DATA['variant'] = DATA['variant'].str.replace('LIN', 'ANK', regex=True)\n",
    "DATA['variant'] = DATA['variant'].str.replace('^ANK[12]$', 'ANK-1', regex=True)\n",
    "DATA['variant'] = DATA['variant'].str.replace('^ANK[12]S$', 'ANK-N', regex=True)\n",
    "DATA['variant'] = DATA['variant'].str.replace('^ANK\\.', 'ANK-1.', regex=True)\n",
    "DATA['variant'] = DATA['variant'].str.replace('^ANKS\\.', 'ANK-N.', regex=True)\n",
    "\n",
    "\n",
    "DATA.loc[DATA['value'] < 0, 'value'] = np.nan\n",
    "DATA.loc[DATA['parameter'] == 'latency', 'value'] /= 1e3 # Convert latency to seconds\n",
    "\n",
    "print(f'=> Commit: {COMMIT}')\n",
    "print('-'*100)\n",
    "\n",
    "print(f'{\"Experiment\": <20}{\"Variant\": <20}{\"Transparent\": <15}{\"Reps\": <7}{\"Parallelism\": <15}{\"Duration\"}')\n",
    "print('-'*100)\n",
    "for label, group in DATA.groupby(['experiment', 'variant', 'transparent', 'parallelism']):\n",
    "    reps = group.rep.nunique()\n",
    "    # Get tmax except logical latency, since this has dummy timestamps\n",
    "    duration = group.query('parameter != \"logical-latency\"').t.max() / 60 \n",
    "    print(f'{label[0]: <20}{label[1]: <20}{label[2]: < 15}{reps: <7}{label[3]: <15}{duration:3.1f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(code=['lr', 'sg', 'carlocal', 'carcloud', 'synthetic1', 'synthetic2'])\n",
    "def selectFigureCode(code):\n",
    "    global FIGURE_CODE\n",
    "    FIGURE_CODE = code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the State-of-the-Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soaComparison2(figsize=(6.5,3.5)):\n",
    "    \n",
    "    def aggregageAll(df, timeFunc=np.mean, nodeFunc=np.mean):\n",
    "        assert DATA.parallelism.nunique() == 1\n",
    "        assert DATA.experiment.nunique() == 1\n",
    "        data = df.copy()\n",
    "        data = data.groupby(['rep', 'parallelism', 'variant', 'transparent', 'node', 'idx']).aggregate({'value': timeFunc})\\\n",
    "                    .groupby(level=['rep', 'parallelism', 'variant', 'transparent']).aggregate({'value': nodeFunc})\\\n",
    "                    .reset_index()\n",
    "        data.columns = ['rep', 'parallelism', 'variant', 'transparent', 'value']\n",
    "        return data\n",
    "\n",
    "    def dataFor(parameter, timeFunc=np.mean, nodeFunc=np.mean):\n",
    "        df = aggregageAll(get(parameter=parameter), timeFunc, nodeFunc)\n",
    "        df = df[(df.variant != 'GL') | (df.transparent == False)]\n",
    "        df.loc[df.transparent == True, 'variant'] += '/T'\n",
    "        return df\n",
    "\n",
    "    assert DATA.parallelism.nunique() == 1\n",
    "    assert DATA.experiment.nunique() == 1\n",
    "    ORDER=None\n",
    "    COLORS=None\n",
    "    ORDER = ['NP', 'GL', 'ANK-1', 'ANK-1/T', 'ANK-N', 'ANK-N/T']\n",
    "    COLORS = ['C0', 'C1', 'C2', 'C2', 'C3', 'C3']\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2, nrows=2, figsize=figsize, sharey=False, sharex=True, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "    hue = None\n",
    "    # Absolute values\n",
    "    sns.barplot(x='variant', y='value', data=dataFor('rate'), ax=axes[0], order=ORDER, palette=COLORS)\n",
    "    sns.barplot(x='variant', y='value', data=dataFor('latency'), ax=axes[1], order=ORDER, palette=COLORS)\n",
    "    sns.barplot(x='variant', y='value', data=dataFor('memory'), ax=axes[2], order=ORDER, palette=COLORS)\n",
    "    sns.barplot(x='variant', y='value', data=dataFor('cpu', nodeFunc=np.sum), ax=axes[3], order=ORDER, palette=COLORS)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xlabel('')\n",
    "    axes[0].set_title('Rate (t/s)', size=12)\n",
    "    axes[1].set_title('Latency (s)', size=12)\n",
    "    axes[2].set_title('Memory (MB)', size=12)\n",
    "    axes[3].set_title('CPU Utilization (%)', size=12)\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        print(f'Percent from NP => [{ax.get_title()}]:', end=' ')\n",
    "        referenceHeight = ax.patches[0].get_height()\n",
    "        ax.patches[3].set_hatch('/////')\n",
    "        ax.patches[5].set_hatch('/////')\n",
    "        for p in ax.patches[1:]:\n",
    "            height = p.get_height()\n",
    "            diff = percentageDiff(height, referenceHeight)\n",
    "        referenceHeight2 = ax.patches[1].get_height()\n",
    "        for p in ax.patches[2:]:\n",
    "            height = p.get_height()\n",
    "            diff = percentageDiff(height, referenceHeight2)\n",
    "            ax.text(p.get_x()+p.get_width()/2,\n",
    "                    height - (height*0.7),\n",
    "                    f'{diff:+2.1f}%',\n",
    "                    ha='center', rotation=90, size=9, family='sans', weight='bold', color='#ffffff') \n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.autofmt_xdate(ha='right', rotation=25)\n",
    "    fig.savefig(f'{REPORT_FOLDER}/eval_soa_comp_{FIGURE_CODE}.pdf', pad_inches=.1, bbox_inches='tight',)\n",
    "    fig.savefig(f'{TEXT_FIGURES_PATH}/eval_soa_comp_{FIGURE_CODE}.pdf', pad_inches=.1, bbox_inches='tight',)\n",
    "soaComparison2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess & Store Logical Latency Data\n",
    "\n",
    "Does some preprocessing on the logical latency of this experiment and stores a new dataframe named using the commit code of the experiment in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGICAL_LATENCY_OUTPUT_DIRECTORY='data/output'\n",
    "\n",
    "def preprocessLogicalLatency():\n",
    "    def secondsToMillis(s):\n",
    "        return s * 1000\n",
    "    def minutesToMillis(m):\n",
    "        return secondsToMillis(m * 60)\n",
    "    def hoursToMillis(h):\n",
    "        return minutesToMillis(60*h)\n",
    "    DELAY_CONSTANTS = {'lr': secondsToMillis(120+30), 'sg': hoursToMillis(48), \n",
    "                       'carlocal': secondsToMillis(6), 'carcloud': secondsToMillis(300)}\n",
    "    delayConstant = DELAY_CONSTANTS[FIGURE_CODE]\n",
    "    df = get(parameter='logical-latency').copy()\n",
    "    assert df.parallelism.nunique() == 1\n",
    "    df = df[df.transparent == False]\n",
    "    df.drop(columns=['kind', 'transparent', 'parameter', 'idx', 'parallelism'], inplace=True)\n",
    "    df['value'] /= delayConstant\n",
    "    outputFile = f'{LOGICAL_LATENCY_OUTPUT_DIRECTORY}/logical-latency-agg-{COMMIT}.csv'\n",
    "    df.to_csv(outputFile, index=False)\n",
    "    print(f'Saved {outputFile}')\n",
    "preprocessLogicalLatency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Logical Latency Comparison\n",
    "\n",
    "Loads logical latency dataframes from multiple experiments and plots a comparison. **The commit codes of the dataframes need to be specified!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLogicalLatency(commits):\n",
    "    NODE_TYPES={'V0': 'SINK', 'V1': 'SOURCE', 'A0': 'SINK-L', 'A1': 'SOURCE-L', '2': 'EDGE'}\n",
    "    QUERY_DICT = {'CarLocalQueries': 'OA', 'CarCloudQueries': 'VT', 'LinearRoadCombined': 'LR', 'SmartGridCombined': 'SG'}\n",
    "    QUERY_ORDER = ['LR', 'SG', 'VT', 'OA']\n",
    "    NODE_ORDER = ['SINK', 'SOURCE', 'EDGE', 'SINK-L', 'SOURCE-L']\n",
    "    dfs = [pd.read_csv(f'{LOGICAL_LATENCY_OUTPUT_DIRECTORY}/logical-latency-agg-{commit}.csv') for commit in commits]\n",
    "    df = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "    df['nodeType'] = df.node.apply(lambda name: NODE_TYPES[name.split('-')[-1]])\n",
    "    df['experiment'] = df.experiment.apply(lambda name: QUERY_DICT[name])\n",
    "    df = pd.pivot_table(df, values=['value'], index=['variant', 'rep', 'experiment', 'nodeType']).reset_index()\n",
    "    g = sns.catplot(x='nodeType', y='value', data=df, hue='experiment', kind='bar', order=NODE_ORDER, \n",
    "                    legend_out=False, col_order=['ANK-1', 'ANK-N'], aspect=1.4, height=2.5, col='variant', hue_order=QUERY_ORDER)\n",
    "    g.set_xlabels('').set_ylabels('Provenance Latency (U)').set_titles('{col_name}')\n",
    "    g.add_legend(title='Query', ncol=2)\n",
    "    g.fig.autofmt_xdate(ha='right', rotation=25)\n",
    "    g.fig.savefig(f'{TEXT_FIGURES_PATH}/eval_logical_latency.pdf', pad_inches=.1, bbox_inches='tight')\n",
    "\n",
    "# ----\n",
    "# Configure: Change commit codes accordingly!\n",
    "# ----\n",
    "plotLogicalLatency(['3c79e14_120_1630', '9a51bd9_118_1455', '8175c59_115_1251', '8175c59_119_0803'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic-1 Plot (varying overlap and provenance size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic1():\n",
    "    def average(df):\n",
    "        assert df.transparent.nunique() == 1\n",
    "        assert df.sourceParallelism.nunique() == 1\n",
    "        assert df.sinkParallelism.nunique() == 1\n",
    "        assert df.parallelism.nunique() == 1\n",
    "        data = df.copy()\n",
    "        data = data.groupby(['rep', 'provenanceOverlap', 'provenanceSize', 'variant', 'parameter', 'node', 'idx']).aggregate({'value': np.mean})\\\n",
    "                    .groupby(level=['rep', 'provenanceOverlap', 'provenanceSize', 'variant', 'parameter']).aggregate({'value': np.mean})\\\n",
    "                    .reset_index()\n",
    "        data.columns = ['rep', 'provenanceOverlap', 'provenanceSize', 'variant', 'parameter', 'value']\n",
    "        return data\n",
    "    ROW_ORDER=['rate', 'latency', 'cpu', 'memory']\n",
    "    g = sns.catplot(col='variant', y='value', x='provenanceSize', row='parameter', data=average(expandSyntheticCols(DATA)), hue='provenanceOverlap', \n",
    "                sharey='row', kind='bar', col_order=['ANK-1', 'ANK-N'], row_order=ROW_ORDER, height=1.5, aspect=1.8,\n",
    "                legend=False)\n",
    "    g.set_axis_labels('Provenance (#tuples)', ROW_ORDER).set_titles(\"{row_name} | {col_name}\")\n",
    "    for i, axes_row in enumerate(g.axes):\n",
    "        for j, axes_col in enumerate(axes_row):\n",
    "            row, col = axes_col.get_title().split('|')\n",
    "\n",
    "            if i == 0:\n",
    "                axes_col.set_title(col.strip())\n",
    "            else:\n",
    "                axes_col.set_title('')\n",
    "\n",
    "            if j == 0:\n",
    "                ylabel = axes_col.get_ylabel()\n",
    "                axes_col.set_ylabel(PARAMETER_LABELS[row.strip()])\n",
    "    for ax in g.axes.flat:\n",
    "        ax.ticklabel_format(axis='y', style='sci', scilimits=(0, 3), useMathText=True)\n",
    "\n",
    "    g.fig.align_ylabels(g.axes[:, 0])\n",
    "    g.add_legend(title='Provenance Overlap (%)', loc='lower center', ncol=3)\n",
    "    g.fig.tight_layout()\n",
    "    g.fig.subplots_adjust(bottom=0.2)\n",
    "    g.fig.savefig(f'{REPORT_FOLDER}/eval_synthetic_comp_{FIGURE_CODE}.pdf', pad_inches=.1, bbox_inches='tight')\n",
    "    g.fig.savefig(f'{TEXT_FIGURES_PATH}/eval_synthetic_comp_{FIGURE_CODE}.pdf', pad_inches=.1, bbox_inches='tight')\n",
    "\n",
    "synthetic1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic-2 Plot (Varying parallelism and #queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic2():\n",
    "    def average(df):\n",
    "        assert df.provenanceOverlap.nunique() == 1\n",
    "        assert df.provenanceSize.nunique() == 1\n",
    "        assert df.parallelism.nunique() == 1\n",
    "        data = df.copy()\n",
    "        data = data.groupby(['rep', 'sourceParallelism', 'sinkParallelism', 'variant', 'parameter', 'node', 'idx']).aggregate({'value': np.mean})\\\n",
    "                    .groupby(level=['rep', 'sourceParallelism', 'sinkParallelism', 'variant', 'parameter']).aggregate({'value': np.mean})\\\n",
    "                    .reset_index()\n",
    "        data.columns = ['rep', 'sourceParallelism', 'sinkParallelism', 'variant', 'parameter', 'value']\n",
    "        return data\n",
    "    ROW_ORDER=['rate', 'latency', 'cpu', 'memory']\n",
    "    g = sns.catplot('sourceParallelism', 'value', kind='bar', row='parameter', data=average(expandSyntheticCols(DATA)), \n",
    "                sharey='row', hue='sinkParallelism', col_order=['ANK-1', 'ANK-N'], row_order=ROW_ORDER,\n",
    "                height=1.5, aspect=1.2,col='variant',legend=False)\n",
    "\n",
    "    g.set_axis_labels('#queries', ROW_ORDER).set_titles(\"{row_name} | {col_name}\")\n",
    "    for i, axes_row in enumerate(g.axes):\n",
    "        for j, axes_col in enumerate(axes_row):\n",
    "            row, col = axes_col.get_title().split('|')\n",
    "\n",
    "            if i == 0:\n",
    "                axes_col.set_title(col.strip())\n",
    "            else:\n",
    "                axes_col.set_title('')\n",
    "\n",
    "            if j == 0:\n",
    "                ylabel = axes_col.get_ylabel()\n",
    "                axes_col.set_ylabel(PARAMETER_LABELS[row.strip()])\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        ax.set_yscale('log')\n",
    "    g.fig.align_ylabels(g.axes[:, 0])\n",
    "    g.add_legend(title='Parallelism', loc='lower center', ncol=5)\n",
    "    g.fig.tight_layout()\n",
    "    g.fig.subplots_adjust(bottom=0.2)\n",
    "    g.fig.savefig(f'{REPORT_FOLDER}/eval_synthetic_comp_{FIGURE_CODE}.pdf', pad_inches=.1, bbox_inches='tight')\n",
    "    g.fig.savefig(f'{TEXT_FIGURES_PATH}/eval_synthetic_comp_{FIGURE_CODE}.pdf', pad_inches=.1, bbox_inches='tight')\n",
    "    \n",
    "synthetic2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
